{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:01:05.484181Z",
     "start_time": "2019-10-15T09:01:05.471215Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from gensim.models.fasttext import FastText\n",
    "from collections import Counter\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "train_path = \"../datasets/AutoMaster_TrainSet.csv\"\n",
    "test_path = \"../datasets/AutoMaster_TestSet.csv\"\n",
    "\n",
    "#切分词之后保存文件\n",
    "train_seg_path = '../datasets/train_seg.csv'\n",
    "test_seg_path = '../datasets/test_seg.csv'\n",
    "\n",
    "#合并列之后保存文件\n",
    "train_seg_merge_path = '../datasets/train_seg_merge.csv'\n",
    "test_seg_merge_path = '../datasets/test_seg_merge.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:00:15.242300Z",
     "start_time": "2019-10-15T08:00:13.592434Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path, encoding='utf-8')\n",
    "df_test = pd.read_csv(test_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:00:18.872900Z",
     "start_time": "2019-10-15T08:00:18.861931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Question</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "      <td>奔驰</td>\n",
       "      <td>奔驰GL级</td>\n",
       "      <td>方向机重，助力泵，方向机都换了还是一样</td>\n",
       "      <td>技师说：[语音]|车主说：新的都换了|车主说：助力泵，方向机|技师说：[语音]|车主说：换了...</td>\n",
       "      <td>随时联系</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>奔驰</td>\n",
       "      <td>奔驰M级</td>\n",
       "      <td>奔驰ML500排气凸轮轴调节错误</td>\n",
       "      <td>技师说：你这个有没有电脑检测故障代码。|车主说：有|技师说：发一下|车主说：发动机之前亮故障...</td>\n",
       "      <td>随时联系</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Q3</td>\n",
       "      <td>宝马</td>\n",
       "      <td>宝马X1(进口)</td>\n",
       "      <td>2010款宝马X1，2011年出厂，2.0排量，通用6L45变速箱，原地换挡位PRND车辆闯...</td>\n",
       "      <td>技师说：你好，4缸自然吸气发动机N46是吧，先挂空档再挂其他档有没有闯动呢，变速箱油液位是否...</td>\n",
       "      <td>行驶没有顿挫的感觉，原地换挡有闯动，刹车踩重没有，这是力的限制的作用，应该没有问题</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Q4</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>牧马人</td>\n",
       "      <td>3.0V6发动机号在什么位置，有照片最好！</td>\n",
       "      <td>技师说：右侧排气管上方，缸体上靠近变速箱|车主说：[图片]|车主说：是不是这个？|车主说：这...</td>\n",
       "      <td>举起车辆，在左前轮这边的缸体上</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Q5</td>\n",
       "      <td>奔驰</td>\n",
       "      <td>奔驰C级</td>\n",
       "      <td>2012款奔驰c180怎么样，维修保养，动力，值得拥有吗</td>\n",
       "      <td>技师说：家庭用车的话，还是可以入手的|技师说：维修保养费用不高|车主说：12年的180市场价...</td>\n",
       "      <td>家庭用车可以入手的，维修保养价格还可以。车况好，价格合理可以入手</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID Brand     Model                                           Question  \\\n",
       "0  Q1    奔驰     奔驰GL级                                方向机重，助力泵，方向机都换了还是一样   \n",
       "1  Q2    奔驰      奔驰M级                                   奔驰ML500排气凸轮轴调节错误   \n",
       "2  Q3    宝马  宝马X1(进口)  2010款宝马X1，2011年出厂，2.0排量，通用6L45变速箱，原地换挡位PRND车辆闯...   \n",
       "3  Q4  Jeep       牧马人                              3.0V6发动机号在什么位置，有照片最好！   \n",
       "4  Q5    奔驰      奔驰C级                       2012款奔驰c180怎么样，维修保养，动力，值得拥有吗   \n",
       "\n",
       "                                            Dialogue  \\\n",
       "0  技师说：[语音]|车主说：新的都换了|车主说：助力泵，方向机|技师说：[语音]|车主说：换了...   \n",
       "1  技师说：你这个有没有电脑检测故障代码。|车主说：有|技师说：发一下|车主说：发动机之前亮故障...   \n",
       "2  技师说：你好，4缸自然吸气发动机N46是吧，先挂空档再挂其他档有没有闯动呢，变速箱油液位是否...   \n",
       "3  技师说：右侧排气管上方，缸体上靠近变速箱|车主说：[图片]|车主说：是不是这个？|车主说：这...   \n",
       "4  技师说：家庭用车的话，还是可以入手的|技师说：维修保养费用不高|车主说：12年的180市场价...   \n",
       "\n",
       "                                      Report  \n",
       "0                                       随时联系  \n",
       "1                                       随时联系  \n",
       "2  行驶没有顿挫的感觉，原地换挡有闯动，刹车踩重没有，这是力的限制的作用，应该没有问题  \n",
       "3                            举起车辆，在左前轮这边的缸体上  \n",
       "4           家庭用车可以入手的，维修保养价格还可以。车况好，价格合理可以入手  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:00:25.911863Z",
     "start_time": "2019-10-15T08:00:25.900890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Question</th>\n",
       "      <th>Dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "      <td>大众(进口)</td>\n",
       "      <td>高尔夫(进口)</td>\n",
       "      <td>我的帕萨特烧机油怎么办怎么办？</td>\n",
       "      <td>技师说：你好，请问你的车跑了多少公里了，如果在保修期内，可以到当地的4店里面进行检查维修。如...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>一汽-大众奥迪</td>\n",
       "      <td>奥迪A6</td>\n",
       "      <td>修一下多少钱是换还是修</td>\n",
       "      <td>技师说：你好师傅！抛光处理一下就好了！50元左右就好了，希望能够帮到你！祝你生活愉快！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Q3</td>\n",
       "      <td>上汽大众</td>\n",
       "      <td>帕萨特</td>\n",
       "      <td>帕萨特领域    喇叭坏了  店里说方向盘里线坏了 换一根两三百不等 感觉太贵</td>\n",
       "      <td>技师说：你好，气囊油丝坏了吗，这个价格不贵。可以更换。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Q4</td>\n",
       "      <td>南京菲亚特</td>\n",
       "      <td>派力奥</td>\n",
       "      <td>发动机漏气会有什么征兆？</td>\n",
       "      <td>技师说：你好！一：发动机没力，并伴有“啪啪”的漏气声音。二：发动机没力，并伴有排气管冒黑烟。...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Q5</td>\n",
       "      <td>东风本田</td>\n",
       "      <td>思铂睿</td>\n",
       "      <td>请问 那天右后胎扎了订，补了胎后跑高速80多开始有点抖，110时速以上抖动明显，以为是未做动...</td>\n",
       "      <td>技师说：你好师傅！可能前轮平衡快脱落或者不平衡造成的！建议前轮做一下动平衡就好了！希望能够帮...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID    Brand    Model                                           Question  \\\n",
       "0  Q1   大众(进口)  高尔夫(进口)                                    我的帕萨特烧机油怎么办怎么办？   \n",
       "1  Q2  一汽-大众奥迪     奥迪A6                                        修一下多少钱是换还是修   \n",
       "2  Q3     上汽大众      帕萨特           帕萨特领域    喇叭坏了  店里说方向盘里线坏了 换一根两三百不等 感觉太贵    \n",
       "3  Q4    南京菲亚特      派力奥                                       发动机漏气会有什么征兆？   \n",
       "4  Q5     东风本田      思铂睿  请问 那天右后胎扎了订，补了胎后跑高速80多开始有点抖，110时速以上抖动明显，以为是未做动...   \n",
       "\n",
       "                                            Dialogue  \n",
       "0  技师说：你好，请问你的车跑了多少公里了，如果在保修期内，可以到当地的4店里面进行检查维修。如...  \n",
       "1        技师说：你好师傅！抛光处理一下就好了！50元左右就好了，希望能够帮到你！祝你生活愉快！  \n",
       "2                        技师说：你好，气囊油丝坏了吗，这个价格不贵。可以更换。  \n",
       "3  技师说：你好！一：发动机没力，并伴有“啪啪”的漏气声音。二：发动机没力，并伴有排气管冒黑烟。...  \n",
       "4  技师说：你好师傅！可能前轮平衡快脱落或者不平衡造成的！建议前轮做一下动平衡就好了！希望能够帮...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词并保存至csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:01:44.449419Z",
     "start_time": "2019-10-15T08:01:44.445459Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = '，：？。? ！! @ # $ % ^ & * ( ) [ ] { } > < = - + ~ ` --- (i (or / ; ;\\' $1 |> \\\n",
    "                    --------- -------------------------------------------------------------------------- \\\n",
    "                    ========================= \\\n",
    "                    0 1 2 3 4 5 6 7 8 9 13 15 30 24 20 \"a\" tk> 95 45'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:01:46.156856Z",
     "start_time": "2019-10-15T08:01:46.152865Z"
    }
   },
   "outputs": [],
   "source": [
    "def process(s):\n",
    "    seg = [i for i in jieba.cut(s) if i not in stop_words ]\n",
    "    return \" \".join(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:01:48.115271Z",
     "start_time": "2019-10-15T08:01:48.110285Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_vocab(df, sort=True, min_count=0, lower=False):\n",
    "    data_columns = df.columns.tolist()\n",
    "    data_seg = []\n",
    "    df_new = pd.DataFrame()\n",
    "    for col in data_columns:\n",
    "        data_col = df[col]\n",
    "        df[col] = df[col].apply(str)\n",
    "        df_new[col] = df[col].apply(process)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:48:02.489509Z",
     "start_time": "2019-10-15T08:45:46.172871Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\86221\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.652 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  QID Brand     Model                                           Question  \\\n",
      "0  Q1    奔驰   奔驰 GL 级                         方向机 重 助力 泵 方向机 都 换 了 还是 一样   \n",
      "1  Q2    奔驰    奔驰 M 级                              奔驰 ML500 排气 凸轮轴 调节 错误   \n",
      "2  Q3    宝马  宝马 X1 进口  2010 款 宝马 X1 2011 年 出厂 2.0 排量 通用 6L45 变速箱 原地 换...   \n",
      "3  Q4  Jeep       牧马人                       3.0 V6 发动机 号 在 什么 位置 有 照片 最好   \n",
      "4  Q5    奔驰    奔驰 C 级                 2012 款 奔驰 c180 怎么样 维修保养 动力 值得 拥有 吗   \n",
      "\n",
      "                                            Dialogue  \\\n",
      "0  技师 说 语音 车主 说 新 的 都 换 了 车主 说 助力 泵 方向机 技师 说 语音 车...   \n",
      "1  技师 说 你 这个 有没有 电脑 检测 故障 代码 车主 说 有 技师 说 发 一下 车主 ...   \n",
      "2  技师 说 你好 缸 自然 吸气 发动机 N46 是 吧 先挂 空档 再 挂 其他 档 有没有...   \n",
      "3  技师 说 右侧 排气管 上方 缸体 上 靠近 变速箱 车主 说 图片 车主 说 是不是 这个...   \n",
      "4  技师 说 家庭 用车 的话 还是 可以 入手 的 技师 说 维修保养 费用 不高 车主 说 ...   \n",
      "\n",
      "                                              Report  \n",
      "0                                              随时 联系  \n",
      "1                                              随时 联系  \n",
      "2  行驶 没有 顿挫 的 感觉 原地 换挡 有 闯动 刹车 踩 重 没有 这 是 力 的 限制 ...  \n",
      "3                             举起 车辆 在 左 前轮 这边 的 缸体 上  \n",
      "4         家庭 用车 可以 入手 的 维修保养 价格 还 可以 车况 好 价格合理 可以 入手  \n",
      "  QID     Brand   Model                                           Question  \\\n",
      "0  Q1     大众 进口  高尔夫 进口                               我 的 帕萨特 烧 机油 怎么办 怎么办   \n",
      "1  Q2  一汽 大众 奥迪   奥迪 A6                                 修 一下 多少 钱 是 换 还是 修   \n",
      "2  Q3     上汽 大众     帕萨特   帕萨特 领域 喇叭 坏 了 店里 说 方向盘 里线 坏 了 换 一根 两三百 不 等 感觉 太贵   \n",
      "3  Q4    南京 菲亚特     派力奥                                   发动机 漏气 会 有 什么 征兆   \n",
      "4  Q5     东风 本田    思铂 睿  请问 那天 右后 胎扎 了 订 补 了 胎后 跑 高速 80 多 开始 有点 抖 110 时...   \n",
      "\n",
      "                                            Dialogue  \n",
      "0  技师 说 你好 请问 你 的 车 跑 了 多少 公里 了 如果 在 保修期 内 可以 到 当...  \n",
      "1  技师 说 你好 师傅 抛光 处理 一下 就 好 了 50 元 左右 就 好 了 希望 能够 ...  \n",
      "2                 技师 说 你好 气囊 油丝坏 了 吗 这个 价格 不 贵 可以 更换  \n",
      "3  技师 说 你好 一 发动机 没力 并 伴有 “ 啪啪 ” 的 漏气 声音 二 发动机 没力 ...  \n",
      "4  技师 说 你好 师傅 可能 前轮 平衡 快 脱落 或者 不 平衡 造成 的 建议 前轮 做 ...  \n"
     ]
    }
   ],
   "source": [
    "df_train_split = build_vocab(df_train)\n",
    "df_test_split = build_vocab(df_test)\n",
    "df_train_split.to_csv(train_seg_path, index=False)\n",
    "df_test_split.to_csv(test_seg_path, index=False)\n",
    "\n",
    "print(df_train_split.head())\n",
    "print(df_test_split.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Word2Vec训练词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:44:34.019516Z",
     "start_time": "2019-10-15T08:44:34.014501Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_dataset(data_train, data_test):\n",
    "   \n",
    "    lines = []\n",
    "    for k in ['Brand', 'Model', 'Question', 'Dialogue', 'Report']:\n",
    "        train_str = list(data_train[k].apply(str).values)\n",
    "        if k != 'Report':\n",
    "            test_str = list(data_test[k].apply(str).values)\n",
    "\n",
    "        train_split = [i.split(' ') for i in train_str]\n",
    "        test_split = [i.split(' ') for i in test_str]\n",
    "\n",
    "        lines.extend(train_split)\n",
    "        lines.extend(test_split)\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:59:34.896408Z",
     "start_time": "2019-10-15T08:59:33.324079Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(train_seg_path)\n",
    "data_test = pd.read_csv(test_seg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:19:31.748681Z",
     "start_time": "2019-10-15T08:19:31.744692Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_bin_path = \"../model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:19:34.036596Z",
     "start_time": "2019-10-15T08:19:34.032574Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:36:52.354395Z",
     "start_time": "2019-10-15T08:36:52.348406Z"
    }
   },
   "outputs": [],
   "source": [
    "def build(train_vocab, out_path=None, embedding_size=100, sentence_path='',\n",
    "          w2v_bin_path=\"w2v.bin\", min_count=5, col_sep='\\t'):\n",
    "#     sentences = extract_sentence(train_seg_path, test_seg_path, col_sep=col_sep)\n",
    "#     save_sentence(sentences, sentence_path)\n",
    "    print('train w2v model...')\n",
    "    # train model\n",
    "    w2v = Word2Vec(sg=1, sentences=train_vocab,\n",
    "                   size=embedding_size, window=5, min_count=min_count, iter=40)\n",
    "    w2v.wv.save_word2vec_format(w2v_bin_path, binary=True)\n",
    "    print(\"save %s ok.\" % w2v_bin_path)\n",
    "    # test\n",
    "    sim = w2v.wv.similarity('奔驰', '宝马')\n",
    "    print('奔驰 vs 宝马 similarity score:', sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:36:54.854704Z",
     "start_time": "2019-10-15T08:36:54.743972Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train w2v model...\n",
      "save ../model.bin ok.\n",
      "奔驰 vs 宝马 similarity score: 0.65706414\n"
     ]
    }
   ],
   "source": [
    "# 训练词向量模型时打开\n",
    "# train_texts = build_dataset(data_train, data_test)\n",
    "# print(len(train_texts))\n",
    "# build(train_texts, w2v_bin_path=w2v_bin_path, min_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:37:05.870470Z",
     "start_time": "2019-10-15T08:37:05.762640Z"
    }
   },
   "outputs": [],
   "source": [
    "#load 词向量模型\n",
    "model = KeyedVectors.load_word2vec_format(w2v_bin_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:37:17.869531Z",
     "start_time": "2019-10-15T08:37:17.740658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('级', 0.7833970189094543),\n",
       " ('SLK', 0.7473358511924744),\n",
       " ('GLK', 0.7150607109069824),\n",
       " ('GLE', 0.7077634334564209),\n",
       " ('E260', 0.6920797824859619),\n",
       " ('AMG', 0.6815943717956543),\n",
       " ('CLS', 0.6804535388946533),\n",
       " ('GLK300', 0.6771597862243652),\n",
       " ('c180', 0.6730772852897644),\n",
       " ('SLC', 0.6694592833518982)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"奔驰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:39:34.832161Z",
     "start_time": "2019-10-15T08:39:34.828174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'车主'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.index2word[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:39:41.616430Z",
     "start_time": "2019-10-15T08:39:41.603448Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22447637, -0.16430447, -0.160667  ,  0.11946642,  0.32137117,\n",
       "       -0.4115743 , -0.1733596 ,  0.18200456,  0.31256333, -0.04483955,\n",
       "       -0.116885  ,  0.00927391,  0.84026146,  0.3283851 , -0.0585743 ,\n",
       "       -0.09963445,  0.03196483,  0.39931512, -0.66921544,  0.2082508 ,\n",
       "       -0.39923197, -0.14274001, -0.17334677,  0.79174125, -0.41516444,\n",
       "        0.46458402, -0.7459004 ,  0.03517142, -0.2646735 , -0.23516215,\n",
       "       -0.22224844,  0.22204933,  0.13188809,  0.1840906 ,  0.24949878,\n",
       "       -0.74379945,  0.7455194 , -0.09887332,  0.33003166, -0.8905177 ,\n",
       "        0.7582478 ,  0.35049307, -0.43025583, -0.7298878 ,  0.7610176 ,\n",
       "        0.17326014,  0.43152225, -0.07353597, -0.37803984,  0.3539339 ,\n",
       "       -0.10800736,  0.3263414 , -0.25117564, -0.03547265, -0.22779697,\n",
       "       -0.21358743,  0.56014603, -0.58048785, -0.37071404,  0.22093923,\n",
       "        0.49489936, -0.6934374 , -0.11059245, -0.11260396, -0.22419325,\n",
       "       -0.33748204, -0.06295139,  0.8563044 , -0.0727259 ,  0.16488495,\n",
       "       -0.30649078,  0.19780749, -0.40589115, -0.24666487, -0.1513587 ,\n",
       "        0.04275352, -0.42450088, -0.14800185,  0.40001354,  0.20589335,\n",
       "        0.00317958,  0.6511358 , -0.46284112,  0.06513549, -0.46930188,\n",
       "       -0.02492726,  0.09672269,  0.18527259,  0.03288786,  0.25052577,\n",
       "       -0.65465975, -0.44375798, -0.32327375, -0.47133127,  0.36945492,\n",
       "        0.04599525, -0.00295026,  0.17198457,  0.04407416, -0.02278039],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.word_vec('别克')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:39:46.710283Z",
     "start_time": "2019-10-15T08:39:46.687324Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.47152788e-03, -1.33668995e-02, -1.26167044e-01, -5.46993949e-02,\n",
       "        8.76659527e-04,  8.35504569e-03, -1.26980662e-01, -5.42780384e-02,\n",
       "       -4.42610011e-02,  5.03077917e-02, -2.37768635e-01, -5.70734143e-02,\n",
       "        2.76433706e-01,  9.73253977e-03,  8.90487656e-02,  6.69513643e-02,\n",
       "       -3.21046710e-01,  1.58806324e-01, -5.97231574e-02,  2.79230237e-01,\n",
       "        1.34209260e-01,  1.30984426e-01,  2.49031745e-02, -1.49520963e-01,\n",
       "       -2.38323063e-02,  1.82858817e-02, -1.47998348e-01,  1.46026630e-02,\n",
       "        2.64978055e-02, -1.35292754e-01, -1.33833498e-01,  1.70370877e-01,\n",
       "        3.96667212e-01, -6.07205853e-02,  1.82222296e-02, -1.83258727e-01,\n",
       "        2.78931502e-02, -1.78094774e-01, -2.50712186e-01,  5.60053959e-02,\n",
       "       -3.93009819e-02,  9.79268923e-02, -1.96002368e-02, -1.64145276e-01,\n",
       "        8.41185972e-02, -8.19877982e-02,  2.80043185e-01, -2.16329053e-01,\n",
       "       -2.14422986e-01,  2.56595314e-01, -1.43586859e-01,  2.60724455e-01,\n",
       "        3.17872949e-02, -2.45402977e-01, -1.88259929e-01,  1.56570710e-02,\n",
       "        1.43380955e-01,  1.44853264e-01, -4.47656929e-01,  1.80006996e-01,\n",
       "       -4.95029390e-02, -5.93417026e-02,  3.37960310e-02, -8.30936357e-02,\n",
       "        1.87882278e-02,  2.21283898e-01, -2.01366842e-01,  1.22553743e-01,\n",
       "       -1.02665834e-01,  3.92537922e-01,  2.03580633e-01,  1.39803186e-01,\n",
       "       -1.18699566e-01, -2.12617010e-01, -4.81423829e-03, -7.05872923e-02,\n",
       "        2.33152494e-01,  3.87989618e-02,  4.58259545e-02,  2.84398925e-02,\n",
       "       -9.74400043e-02, -1.57952338e-01, -1.12237364e-01, -1.60363480e-01,\n",
       "        2.38453105e-01, -3.05681266e-02,  3.13372314e-01,  3.21569145e-01,\n",
       "        5.55385798e-02,  1.62568521e-02,  1.26281083e-01,  3.66952358e-04,\n",
       "        2.32295647e-01, -3.77744943e-01, -1.14509827e-02,  3.06095839e-01,\n",
       "       -9.91869420e-02, -4.95294295e-02,  1.92478914e-02, -1.01216331e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vectors[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Sentences to Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T07:47:04.030410Z",
     "start_time": "2019-10-15T07:47:03.951893Z"
    }
   },
   "outputs": [],
   "source": [
    "# def word2index(model):\n",
    "#     \"\"\"\n",
    "#     建立词-->索引字典\n",
    "#     \"\"\"\n",
    "#     word2index = {}\n",
    "#     for i in range(len(model.vocab)):\n",
    "#         word = model.index2word[i]\n",
    "#         word2index[word] = i\n",
    "#     return word2index\n",
    "\n",
    "# word2index_dic = word2index(model)\n",
    "# word2index_dic['<start>'] = len(word2index_dic)\n",
    "# word2index_dic['<end>'] = len(word2index_dic) + 1\n",
    "\n",
    "# def process_split(sen):\n",
    "#     \"\"\"将句子转为ids\n",
    "#     \"\"\"\n",
    "#     sen_list = []\n",
    "#     if sen is not None:\n",
    "#         sen_list = [str(word2index_dic[i]) for i in str(sen).split(' ')]\n",
    "#     return ' '.join(sen_list)\n",
    "\n",
    "# def convertSentences2Ids(df):\n",
    "#     df_process = df.copy()\n",
    "#     for col in ['Brand', 'Model', 'Question', 'Dialogue', 'Report']:\n",
    "#         df_col = df_process[col].apply(process_split)\n",
    "#         df_process[col + '_' + 'index'] = df_col\n",
    "#     return df_process\n",
    "\n",
    "# df_index = convertSentences2Ids(df_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分别合并train和test的前几列作为input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:59:46.699151Z",
     "start_time": "2019-10-15T08:59:46.690147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Question</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "      <td>奔驰</td>\n",
       "      <td>奔驰 GL 级</td>\n",
       "      <td>方向机 重 助力 泵 方向机 都 换 了 还是 一样</td>\n",
       "      <td>技师 说 语音 车主 说 新 的 都 换 了 车主 说 助力 泵 方向机 技师 说 语音 车...</td>\n",
       "      <td>随时 联系</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>奔驰</td>\n",
       "      <td>奔驰 M 级</td>\n",
       "      <td>奔驰 ML500 排气 凸轮轴 调节 错误</td>\n",
       "      <td>技师 说 你 这个 有没有 电脑 检测 故障 代码 车主 说 有 技师 说 发 一下 车主 ...</td>\n",
       "      <td>随时 联系</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Q3</td>\n",
       "      <td>宝马</td>\n",
       "      <td>宝马 X1 进口</td>\n",
       "      <td>2010 款 宝马 X1 2011 年 出厂 2.0 排量 通用 6L45 变速箱 原地 换...</td>\n",
       "      <td>技师 说 你好 缸 自然 吸气 发动机 N46 是 吧 先挂 空档 再 挂 其他 档 有没有...</td>\n",
       "      <td>行驶 没有 顿挫 的 感觉 原地 换挡 有 闯动 刹车 踩 重 没有 这 是 力 的 限制 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Q4</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>牧马人</td>\n",
       "      <td>3.0 V6 发动机 号 在 什么 位置 有 照片 最好</td>\n",
       "      <td>技师 说 右侧 排气管 上方 缸体 上 靠近 变速箱 车主 说 图片 车主 说 是不是 这个...</td>\n",
       "      <td>举起 车辆 在 左 前轮 这边 的 缸体 上</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Q5</td>\n",
       "      <td>奔驰</td>\n",
       "      <td>奔驰 C 级</td>\n",
       "      <td>2012 款 奔驰 c180 怎么样 维修保养 动力 值得 拥有 吗</td>\n",
       "      <td>技师 说 家庭 用车 的话 还是 可以 入手 的 技师 说 维修保养 费用 不高 车主 说 ...</td>\n",
       "      <td>家庭 用车 可以 入手 的 维修保养 价格 还 可以 车况 好 价格合理 可以 入手</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID Brand     Model                                           Question  \\\n",
       "0  Q1    奔驰   奔驰 GL 级                         方向机 重 助力 泵 方向机 都 换 了 还是 一样   \n",
       "1  Q2    奔驰    奔驰 M 级                              奔驰 ML500 排气 凸轮轴 调节 错误   \n",
       "2  Q3    宝马  宝马 X1 进口  2010 款 宝马 X1 2011 年 出厂 2.0 排量 通用 6L45 变速箱 原地 换...   \n",
       "3  Q4  Jeep       牧马人                       3.0 V6 发动机 号 在 什么 位置 有 照片 最好   \n",
       "4  Q5    奔驰    奔驰 C 级                 2012 款 奔驰 c180 怎么样 维修保养 动力 值得 拥有 吗   \n",
       "\n",
       "                                            Dialogue  \\\n",
       "0  技师 说 语音 车主 说 新 的 都 换 了 车主 说 助力 泵 方向机 技师 说 语音 车...   \n",
       "1  技师 说 你 这个 有没有 电脑 检测 故障 代码 车主 说 有 技师 说 发 一下 车主 ...   \n",
       "2  技师 说 你好 缸 自然 吸气 发动机 N46 是 吧 先挂 空档 再 挂 其他 档 有没有...   \n",
       "3  技师 说 右侧 排气管 上方 缸体 上 靠近 变速箱 车主 说 图片 车主 说 是不是 这个...   \n",
       "4  技师 说 家庭 用车 的话 还是 可以 入手 的 技师 说 维修保养 费用 不高 车主 说 ...   \n",
       "\n",
       "                                              Report  \n",
       "0                                              随时 联系  \n",
       "1                                              随时 联系  \n",
       "2  行驶 没有 顿挫 的 感觉 原地 换挡 有 闯动 刹车 踩 重 没有 这 是 力 的 限制 ...  \n",
       "3                             举起 车辆 在 左 前轮 这边 的 缸体 上  \n",
       "4         家庭 用车 可以 入手 的 维修保养 价格 还 可以 车况 好 价格合理 可以 入手  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:59:49.007950Z",
     "start_time": "2019-10-15T08:59:48.997991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Question</th>\n",
       "      <th>Dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "      <td>大众 进口</td>\n",
       "      <td>高尔夫 进口</td>\n",
       "      <td>我 的 帕萨特 烧 机油 怎么办 怎么办</td>\n",
       "      <td>技师 说 你好 请问 你 的 车 跑 了 多少 公里 了 如果 在 保修期 内 可以 到 当...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>一汽 大众 奥迪</td>\n",
       "      <td>奥迪 A6</td>\n",
       "      <td>修 一下 多少 钱 是 换 还是 修</td>\n",
       "      <td>技师 说 你好 师傅 抛光 处理 一下 就 好 了 50 元 左右 就 好 了 希望 能够 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Q3</td>\n",
       "      <td>上汽 大众</td>\n",
       "      <td>帕萨特</td>\n",
       "      <td>帕萨特 领域 喇叭 坏 了 店里 说 方向盘 里线 坏 了 换 一根 两三百 不 等 感觉 太贵</td>\n",
       "      <td>技师 说 你好 气囊 油丝坏 了 吗 这个 价格 不 贵 可以 更换</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Q4</td>\n",
       "      <td>南京 菲亚特</td>\n",
       "      <td>派力奥</td>\n",
       "      <td>发动机 漏气 会 有 什么 征兆</td>\n",
       "      <td>技师 说 你好 一 发动机 没力 并 伴有 “ 啪啪 ” 的 漏气 声音 二 发动机 没力 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Q5</td>\n",
       "      <td>东风 本田</td>\n",
       "      <td>思铂 睿</td>\n",
       "      <td>请问 那天 右后 胎扎 了 订 补 了 胎后 跑 高速 80 多 开始 有点 抖 110 时...</td>\n",
       "      <td>技师 说 你好 师傅 可能 前轮 平衡 快 脱落 或者 不 平衡 造成 的 建议 前轮 做 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID     Brand   Model                                           Question  \\\n",
       "0  Q1     大众 进口  高尔夫 进口                               我 的 帕萨特 烧 机油 怎么办 怎么办   \n",
       "1  Q2  一汽 大众 奥迪   奥迪 A6                                 修 一下 多少 钱 是 换 还是 修   \n",
       "2  Q3     上汽 大众     帕萨特   帕萨特 领域 喇叭 坏 了 店里 说 方向盘 里线 坏 了 换 一根 两三百 不 等 感觉 太贵   \n",
       "3  Q4    南京 菲亚特     派力奥                                   发动机 漏气 会 有 什么 征兆   \n",
       "4  Q5     东风 本田    思铂 睿  请问 那天 右后 胎扎 了 订 补 了 胎后 跑 高速 80 多 开始 有点 抖 110 时...   \n",
       "\n",
       "                                            Dialogue  \n",
       "0  技师 说 你好 请问 你 的 车 跑 了 多少 公里 了 如果 在 保修期 内 可以 到 当...  \n",
       "1  技师 说 你好 师傅 抛光 处理 一下 就 好 了 50 元 左右 就 好 了 希望 能够 ...  \n",
       "2                 技师 说 你好 气囊 油丝坏 了 吗 这个 价格 不 贵 可以 更换  \n",
       "3  技师 说 你好 一 发动机 没力 并 伴有 “ 啪啪 ” 的 漏气 声音 二 发动机 没力 ...  \n",
       "4  技师 说 你好 师傅 可能 前轮 平衡 快 脱落 或者 不 平衡 造成 的 建议 前轮 做 ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:59:51.267908Z",
     "start_time": "2019-10-15T08:59:51.261945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82943, 6), (20000, 5))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:59:53.559783Z",
     "start_time": "2019-10-15T08:59:53.508914Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.dropna(axis=0, how='any', inplace=True)\n",
    "data_test.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:59:55.818738Z",
     "start_time": "2019-10-15T08:59:55.813752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81559, 6), (19987, 5))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:59:58.377691Z",
     "start_time": "2019-10-15T08:59:58.119587Z"
    }
   },
   "outputs": [],
   "source": [
    "#合并除report的字段\n",
    "data_train['input'] = data_train['Brand'] + ' ' + data_train['Model'] + ' ' + data_train['Question'] + ' ' + data_train['Dialogue']\n",
    "data_train.drop(['Brand', 'Model', 'Question', 'Dialogue'], axis=1, inplace=True)\n",
    "\n",
    "data_test['input'] = data_test['Brand'] + ' ' + data_test['Model'] + ' ' + data_test['Question'] + ' ' + data_test['Dialogue']\n",
    "data_test.drop(['Brand', 'Model', 'Question', 'Dialogue'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:00:00.639228Z",
     "start_time": "2019-10-15T09:00:00.628268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Report</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "      <td>随时 联系</td>\n",
       "      <td>奔驰 奔驰 GL 级 方向机 重 助力 泵 方向机 都 换 了 还是 一样 技师 说 语音 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>随时 联系</td>\n",
       "      <td>奔驰 奔驰 M 级 奔驰 ML500 排气 凸轮轴 调节 错误 技师 说 你 这个 有没有 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Q3</td>\n",
       "      <td>行驶 没有 顿挫 的 感觉 原地 换挡 有 闯动 刹车 踩 重 没有 这 是 力 的 限制 ...</td>\n",
       "      <td>宝马 宝马 X1 进口 2010 款 宝马 X1 2011 年 出厂 2.0 排量 通用 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Q4</td>\n",
       "      <td>举起 车辆 在 左 前轮 这边 的 缸体 上</td>\n",
       "      <td>Jeep 牧马人 3.0 V6 发动机 号 在 什么 位置 有 照片 最好 技师 说 右侧 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Q5</td>\n",
       "      <td>家庭 用车 可以 入手 的 维修保养 价格 还 可以 车况 好 价格合理 可以 入手</td>\n",
       "      <td>奔驰 奔驰 C 级 2012 款 奔驰 c180 怎么样 维修保养 动力 值得 拥有 吗 技...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID                                             Report  \\\n",
       "0  Q1                                              随时 联系   \n",
       "1  Q2                                              随时 联系   \n",
       "2  Q3  行驶 没有 顿挫 的 感觉 原地 换挡 有 闯动 刹车 踩 重 没有 这 是 力 的 限制 ...   \n",
       "3  Q4                             举起 车辆 在 左 前轮 这边 的 缸体 上   \n",
       "4  Q5         家庭 用车 可以 入手 的 维修保养 价格 还 可以 车况 好 价格合理 可以 入手   \n",
       "\n",
       "                                               input  \n",
       "0  奔驰 奔驰 GL 级 方向机 重 助力 泵 方向机 都 换 了 还是 一样 技师 说 语音 ...  \n",
       "1  奔驰 奔驰 M 级 奔驰 ML500 排气 凸轮轴 调节 错误 技师 说 你 这个 有没有 ...  \n",
       "2  宝马 宝马 X1 进口 2010 款 宝马 X1 2011 年 出厂 2.0 排量 通用 6...  \n",
       "3  Jeep 牧马人 3.0 V6 发动机 号 在 什么 位置 有 照片 最好 技师 说 右侧 ...  \n",
       "4  奔驰 奔驰 C 级 2012 款 奔驰 c180 怎么样 维修保养 动力 值得 拥有 吗 技...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:00:02.899185Z",
     "start_time": "2019-10-15T09:00:02.890208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "      <td>大众 进口 高尔夫 进口 我 的 帕萨特 烧 机油 怎么办 怎么办 技师 说 你好 请问 你...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>一汽 大众 奥迪 奥迪 A6 修 一下 多少 钱 是 换 还是 修 技师 说 你好 师傅 抛...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Q3</td>\n",
       "      <td>上汽 大众 帕萨特 帕萨特 领域 喇叭 坏 了 店里 说 方向盘 里线 坏 了 换 一根 两...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Q4</td>\n",
       "      <td>南京 菲亚特 派力奥 发动机 漏气 会 有 什么 征兆 技师 说 你好 一 发动机 没力 并...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Q5</td>\n",
       "      <td>东风 本田 思铂 睿 请问 那天 右后 胎扎 了 订 补 了 胎后 跑 高速 80 多 开始...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID                                              input\n",
       "0  Q1  大众 进口 高尔夫 进口 我 的 帕萨特 烧 机油 怎么办 怎么办 技师 说 你好 请问 你...\n",
       "1  Q2  一汽 大众 奥迪 奥迪 A6 修 一下 多少 钱 是 换 还是 修 技师 说 你好 师傅 抛...\n",
       "2  Q3  上汽 大众 帕萨特 帕萨特 领域 喇叭 坏 了 店里 说 方向盘 里线 坏 了 换 一根 两...\n",
       "3  Q4  南京 菲亚特 派力奥 发动机 漏气 会 有 什么 征兆 技师 说 你好 一 发动机 没力 并...\n",
       "4  Q5  东风 本田 思铂 睿 请问 那天 右后 胎扎 了 订 补 了 胎后 跑 高速 80 多 开始..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:00:06.486595Z",
     "start_time": "2019-10-15T09:00:05.257879Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.to_csv(train_seg_merge_path, index=False)\n",
    "data_test.to_csv(test_seg_merge_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:00:43.116622Z",
     "start_time": "2019-10-15T09:00:41.628197Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train_merge = pd.read_csv(train_seg_merge_path)\n",
    "data_test_merge = pd.read_csv(test_seg_merge_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:00:45.453195Z",
     "start_time": "2019-10-15T09:00:45.443230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Report</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "      <td>随时 联系</td>\n",
       "      <td>奔驰 奔驰 GL 级 方向机 重 助力 泵 方向机 都 换 了 还是 一样 技师 说 语音 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>随时 联系</td>\n",
       "      <td>奔驰 奔驰 M 级 奔驰 ML500 排气 凸轮轴 调节 错误 技师 说 你 这个 有没有 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Q3</td>\n",
       "      <td>行驶 没有 顿挫 的 感觉 原地 换挡 有 闯动 刹车 踩 重 没有 这 是 力 的 限制 ...</td>\n",
       "      <td>宝马 宝马 X1 进口 2010 款 宝马 X1 2011 年 出厂 2.0 排量 通用 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Q4</td>\n",
       "      <td>举起 车辆 在 左 前轮 这边 的 缸体 上</td>\n",
       "      <td>Jeep 牧马人 3.0 V6 发动机 号 在 什么 位置 有 照片 最好 技师 说 右侧 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Q5</td>\n",
       "      <td>家庭 用车 可以 入手 的 维修保养 价格 还 可以 车况 好 价格合理 可以 入手</td>\n",
       "      <td>奔驰 奔驰 C 级 2012 款 奔驰 c180 怎么样 维修保养 动力 值得 拥有 吗 技...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID                                             Report  \\\n",
       "0  Q1                                              随时 联系   \n",
       "1  Q2                                              随时 联系   \n",
       "2  Q3  行驶 没有 顿挫 的 感觉 原地 换挡 有 闯动 刹车 踩 重 没有 这 是 力 的 限制 ...   \n",
       "3  Q4                             举起 车辆 在 左 前轮 这边 的 缸体 上   \n",
       "4  Q5         家庭 用车 可以 入手 的 维修保养 价格 还 可以 车况 好 价格合理 可以 入手   \n",
       "\n",
       "                                               input  \n",
       "0  奔驰 奔驰 GL 级 方向机 重 助力 泵 方向机 都 换 了 还是 一样 技师 说 语音 ...  \n",
       "1  奔驰 奔驰 M 级 奔驰 ML500 排气 凸轮轴 调节 错误 技师 说 你 这个 有没有 ...  \n",
       "2  宝马 宝马 X1 进口 2010 款 宝马 X1 2011 年 出厂 2.0 排量 通用 6...  \n",
       "3  Jeep 牧马人 3.0 V6 发动机 号 在 什么 位置 有 照片 最好 技师 说 右侧 ...  \n",
       "4  奔驰 奔驰 C 级 2012 款 奔驰 c180 怎么样 维修保养 动力 值得 拥有 吗 技...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:00:47.729094Z",
     "start_time": "2019-10-15T09:00:47.720118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "      <td>大众 进口 高尔夫 进口 我 的 帕萨特 烧 机油 怎么办 怎么办 技师 说 你好 请问 你...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>一汽 大众 奥迪 奥迪 A6 修 一下 多少 钱 是 换 还是 修 技师 说 你好 师傅 抛...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Q3</td>\n",
       "      <td>上汽 大众 帕萨特 帕萨特 领域 喇叭 坏 了 店里 说 方向盘 里线 坏 了 换 一根 两...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Q4</td>\n",
       "      <td>南京 菲亚特 派力奥 发动机 漏气 会 有 什么 征兆 技师 说 你好 一 发动机 没力 并...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Q5</td>\n",
       "      <td>东风 本田 思铂 睿 请问 那天 右后 胎扎 了 订 补 了 胎后 跑 高速 80 多 开始...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID                                              input\n",
       "0  Q1  大众 进口 高尔夫 进口 我 的 帕萨特 烧 机油 怎么办 怎么办 技师 说 你好 请问 你...\n",
       "1  Q2  一汽 大众 奥迪 奥迪 A6 修 一下 多少 钱 是 换 还是 修 技师 说 你好 师傅 抛...\n",
       "2  Q3  上汽 大众 帕萨特 帕萨特 领域 喇叭 坏 了 店里 说 方向盘 里线 坏 了 换 一根 两...\n",
       "3  Q4  南京 菲亚特 派力奥 发动机 漏气 会 有 什么 征兆 技师 说 你好 一 发动机 没力 并...\n",
       "4  Q5  东风 本田 思铂 睿 请问 那天 右后 胎扎 了 订 补 了 胎后 跑 高速 80 多 开始..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:00:56.591907Z",
     "start_time": "2019-10-15T09:00:56.587893Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_word(w):\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "def preprocess_id(w):\n",
    "    w = str(len(word2index_dic)) + ' ' + w + ' ' + str(len(word2index_dic) + 1)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:02:02.632882Z",
     "start_time": "2019-10-15T09:01:58.173121Z"
    }
   },
   "outputs": [],
   "source": [
    "#添加<start><end>\n",
    "data_train_merge['input'] = data_train_merge['input'].apply(preprocess_word).copy()\n",
    "data_train_merge['Report'] = data_train_merge['Report'].apply(preprocess_word).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:02:09.445258Z",
     "start_time": "2019-10-15T09:02:09.437251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Report</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "      <td>&lt;start&gt; 随时 联系 &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; 奔驰 奔驰 GL 级 方向机 重 助力 泵 方向机 都 换 了 还是 一样 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>&lt;start&gt; 随时 联系 &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; 奔驰 奔驰 M 级 奔驰 ML500 排气 凸轮轴 调节 错误 技师 说 你...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Q3</td>\n",
       "      <td>&lt;start&gt; 行驶 没有 顿挫 的 感觉 原地 换挡 有 闯动 刹车 踩 重 没有 这 是...</td>\n",
       "      <td>&lt;start&gt; 宝马 宝马 X1 进口 2010 款 宝马 X1 2011 年 出厂 2 ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Q4</td>\n",
       "      <td>&lt;start&gt; 举起 车辆 在 左 前轮 这边 的 缸体 上 &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; Jeep 牧马人 3 . 0 V6 发动机 号 在 什么 位置 有 照片 最...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Q5</td>\n",
       "      <td>&lt;start&gt; 家庭 用车 可以 入手 的 维修保养 价格 还 可以 车况 好 价格合理 可...</td>\n",
       "      <td>&lt;start&gt; 奔驰 奔驰 C 级 2012 款 奔驰 c180 怎么样 维修保养 动力 值...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID                                             Report  \\\n",
       "0  Q1                                <start> 随时 联系 <end>   \n",
       "1  Q2                                <start> 随时 联系 <end>   \n",
       "2  Q3  <start> 行驶 没有 顿挫 的 感觉 原地 换挡 有 闯动 刹车 踩 重 没有 这 是...   \n",
       "3  Q4               <start> 举起 车辆 在 左 前轮 这边 的 缸体 上 <end>   \n",
       "4  Q5  <start> 家庭 用车 可以 入手 的 维修保养 价格 还 可以 车况 好 价格合理 可...   \n",
       "\n",
       "                                               input  \n",
       "0  <start> 奔驰 奔驰 GL 级 方向机 重 助力 泵 方向机 都 换 了 还是 一样 ...  \n",
       "1  <start> 奔驰 奔驰 M 级 奔驰 ML500 排气 凸轮轴 调节 错误 技师 说 你...  \n",
       "2  <start> 宝马 宝马 X1 进口 2010 款 宝马 X1 2011 年 出厂 2 ....  \n",
       "3  <start> Jeep 牧马人 3 . 0 V6 发动机 号 在 什么 位置 有 照片 最...  \n",
       "4  <start> 奔驰 奔驰 C 级 2012 款 奔驰 c180 怎么样 维修保养 动力 值...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:03:30.374662Z",
     "start_time": "2019-10-15T09:03:30.332775Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(texts, max_len):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', num_words=max_words_size)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    \n",
    "    word_index = tokenizer.word_index\n",
    "    tensor = tokenizer.texts_to_sequences(texts)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, max_len, padding='post')\n",
    "    return tensor, word_index, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:04:58.542807Z",
     "start_time": "2019-10-15T09:04:57.917180Z"
    }
   },
   "outputs": [],
   "source": [
    "max_words_size = 30000\n",
    "max_input_size = 500\n",
    "max_target_size = 50\n",
    "\n",
    "dataset_num = 128\n",
    "\n",
    "input_data = data_train_merge['input'].apply(str).values.tolist()\n",
    "target_data = data_train_merge['Report'].apply(str).values.tolist()\n",
    "tensor_input, word_index_input, tokenizer_input = tokenize(input_data, max_input_size)\n",
    "tensor_target, word_index_target, tokenizer_target = tokenize(target_data, max_target_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81559, 81559)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_data), len(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:05:01.611693Z",
     "start_time": "2019-10-15T09:05:01.604713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_length(tensor): return max(len(t) for t in tensor)\n",
    "max_length_targ, max_length_inp = max_length(tensor_target), max_length(tensor_input)\n",
    "max_length_inp, max_length_targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:05:05.107348Z",
     "start_time": "2019-10-15T09:05:05.068453Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_embedding(word_index_input, word_index_target, path='', embed_size=100):\n",
    "    \n",
    "#     num_input_en = min(max_words_size, len(word_index_input)) + 1\n",
    "    num_input_en = len(word_index_input) + 1\n",
    "    encoder_embedding = np.zeros((num_input_en, embed_size))\n",
    "    for word, id in word_index_input.items():\n",
    "        if word not in model.vocab:\n",
    "            word_vec = np.random.uniform(-0.25, 0.25, embed_size)\n",
    "        else:\n",
    "            word_vec = model.word_vec(word)\n",
    "        encoder_embedding[id] = word_vec\n",
    "    \n",
    "    num_input_de = len(word_index_target) + 1\n",
    "#     num_input_de = min(max_words_size, len(word_index_target)) + 1\n",
    "    decoder_embedding = np.zeros((num_input_de, embed_size))\n",
    "    for word, id in word_index_target.items():\n",
    "        if word not in model.vocab:\n",
    "            word_vec = np.random.uniform(-0.25, 0.25, embed_size)\n",
    "        else:\n",
    "            word_vec = model.word_vec(word)\n",
    "        decoder_embedding[id] = word_vec\n",
    "    return encoder_embedding, decoder_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:05:48.120894Z",
     "start_time": "2019-10-15T09:05:48.045094Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_embedding, decoder_embedding = get_embedding( word_index_input, word_index_target, embed_size=embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:05:50.398799Z",
     "start_time": "2019-10-15T09:05:50.393812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100150, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:05:52.927520Z",
     "start_time": "2019-10-15T09:05:52.923502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24085, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:06:24.003254Z",
     "start_time": "2019-10-15T09:06:23.918041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 102 26 26\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(tensor_input[:dataset_num], tensor_target[:dataset_num], test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:07:07.576200Z",
     "start_time": "2019-10-15T09:07:06.812580Z"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 16\n",
    "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n",
    "embedding_dim = embedding_size\n",
    "units = 128\n",
    "vocab_inp_size = len(word_index_input) + 1\n",
    "vocab_tar_size = len(word_index_target) + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:07:11.211873Z",
     "start_time": "2019-10-15T09:07:11.148748Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, embedding_matrix):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix])\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, sentences, hidden):\n",
    "        embed = self.embedding(sentences)\n",
    "        output, state_h = self.gru(embed, initial_state = hidden)\n",
    "        return output, state_h\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:07:13.598159Z",
     "start_time": "2019-10-15T09:07:13.462868Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE, encoder_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:07:15.952773Z",
     "start_time": "2019-10-15T09:07:15.947755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100150, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:07:18.211731Z",
     "start_time": "2019-10-15T09:07:18.206716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100150, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_inp_size, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:07:28.763722Z",
     "start_time": "2019-10-15T09:07:20.497591Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (16, 500, 128)\n",
      "Encoder Hidden state shape: (batch size, units) (16, 128)\n"
     ]
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden= encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:07:31.088683Z",
     "start_time": "2019-10-15T09:07:31.051604Z"
    }
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    # other attention is LuongAttention\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:07:33.792098Z",
     "start_time": "2019-10-15T09:07:33.443229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (16, 128)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (16, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:07:36.067158Z",
     "start_time": "2019-10-15T09:07:36.059148Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, embedding_matrix):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix])\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:07:39.207159Z",
     "start_time": "2019-10-15T09:07:38.318110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (16, 24085)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, decoder_embedding)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((16, 1)), sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:07:41.582707Z",
     "start_time": "2019-10-15T09:07:41.564727Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:07:43.897518Z",
     "start_time": "2019-10-15T09:07:43.893503Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = '/checkpoints/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:07:46.245242Z",
     "start_time": "2019-10-15T09:07:46.236268Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([tokenizer_target.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:,t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:,t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-15T09:07:48.845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.5872\n",
      "Epoch 1 Loss 5.0761\n",
      "Time taken for 1 epoch 65.54161286354065 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测测试集Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-15T09:08:28.012Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_word(sentence)\n",
    "\n",
    "    inputs = [tokenizer_input.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([tokenizer_target.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += tokenizer_target.index_word[predicted_id] + ' '\n",
    "\n",
    "        if tokenizer_target.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T07:14:23.179480Z",
     "start_time": "2019-10-15T07:14:23.173494Z"
    }
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-15T09:08:52.124Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "#     plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T07:11:01.827570Z",
     "start_time": "2019-10-15T07:11:01.759724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x2de7fd0e048>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_report(sentence):\n",
    "    return evaluate(sentence.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ',\n",
       " '你好 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 ']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此处预测训练集Reports\n",
    "predict_train_reports = []\n",
    "for sentence in data_train_merge['input'][:20]:\n",
    "    result, _, _ = predict_report(sentence)\n",
    "    predict_train_reports.append(result)\n",
    "predict_train_reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 此处预测测试集Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'盖出'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-2fb37f0d25ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpredict_test_report\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_test_merge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mpredict_test_report\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredict_test_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-66-3846e5b8803a>\u001b[0m in \u001b[0;36mpredict_report\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-41-550b29caa6ba>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokenizer_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n\u001b[0;32m      8\u001b[0m                                                            \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length_inp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-550b29caa6ba>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokenizer_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n\u001b[0;32m      8\u001b[0m                                                            \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length_inp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '盖出'"
     ]
    }
   ],
   "source": [
    "def predict_report(sentence):\n",
    "    return evaluate(sentence.lower())\n",
    "\n",
    "predict_test_report = []\n",
    "for sentence in data_test_merge['input'][:20]:\n",
    "    result, _, _ = predict_report(sentence)\n",
    "    predict_test_report.append(result)\n",
    "predict_test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "会出现测试集中的词语在训练集的input中未出现的情况，这点改如何处理？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_2.0]",
   "language": "python",
   "name": "conda-env-tensorflow_2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
